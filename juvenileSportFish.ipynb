{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Original Excel source file from the data provider stored on a GCOOS WAF folder\n",
    "sourcefile = 'https://gcoos4.geos.tamu.edu/WAF/MBON/JuvenileSportFish/2016JuvenileSportfishNOAA.xlsx'\n",
    "\n",
    "# -- Read the \"Sportfish Data\" sheet from the Excel file\n",
    "# --\n",
    "df_spt = pd.read_excel(sourcefile, sheet_name='Sportfish Data')\n",
    "\n",
    "# Read the \"Collection Stn Data\" sheet from the Excel file\n",
    "# --\n",
    "df_cln = pd.read_excel(sourcefile, sheet_name='Collection Stn Data')\n",
    "\n",
    "# -- Read the \"Species Code\" sheet from the Excel file\n",
    "# --\n",
    "df_spc = pd.read_excel(sourcefile, sheet_name='Species Code')\n",
    "\n",
    "# -- Read the \"All Data\" sheet from the Excel file\n",
    "# --\n",
    "df_all = pd.read_excel(sourcefile, sheet_name='All Data')\n",
    "# Replace special chars in column names\n",
    "df_all.columns = [col.replace('%', 'percent') for col in df_all.columns]\n",
    "\n",
    "# Drop columns that are not needed\n",
    "df_all.drop(columns=['Cyn (lengths 30-200 mm)','Cyn (lengths 30-200 mm) pres/abs only','Lug (lengths 30-260 mm)  pres/abs only'], inplace=True)\n",
    "# Rename some columns\n",
    "df_all = df_all.rename(columns={'Cyn ALL Lengths': 'cyn', 'Lug (lengths 30-260 mm)': 'lug'})\n",
    "# List of count columns to rename and melt:\n",
    "count_cols = [ 'Ari','Arp','Bab','Chf','cyn','Epi','Has','Hie','Hpa','Hyp','Lam','Lar','lug','Lum','Lun','Lus','Mym','Occ','Paa','Pab','Pal','Poc','Scb','Sco','Sev','Spa']\n",
    "# Make all lower case (to match with species code list later)\n",
    "for acol in count_cols:\n",
    "    df_all = df_all.rename(columns={acol: acol.lower()})\n",
    "counts_lower = [item.lower() for item in count_cols]\n",
    "\n",
    "# -- Melt the dataframe to long form\n",
    "# --\n",
    "# Melt species count columns to just SpeciesCode and SpeciesCount)\n",
    "df_long = pd.melt(df_all,\n",
    "                  id_vars=[col for col in df_all.columns if col not in counts_lower], # other columns to keep\n",
    "                  value_vars=counts_lower,        # species columns\n",
    "                  var_name='SpeciesCode', \n",
    "                  value_name='SpeciesCount')\n",
    "\n",
    "# -- Fix Time\n",
    "# -- \n",
    "# Fill missing times with a default\n",
    "df_long['Time'] = df_long['Time'].fillna(1200)\n",
    "# Convert to integer (from float)\n",
    "df_long['Time'] = df_long['Time'].astype('int')\n",
    "\n",
    "# -- Add a Datetime field (date and time)\n",
    "# --\n",
    "df_long['timestr'] = df_long['Time'].astype(str)\n",
    "df_long['minute'] = df_long['timestr'].str[-2:]\n",
    "# Clean dirty data: minute has values like \"78\", should probably be \"18\"\n",
    "def replace_second_last_char_if_target(s, new_char, target_char):\n",
    "    s = str(s)  # Ensure it's a string\n",
    "    if len(s) < 2 or s[-2] != target_char:\n",
    "        return s\n",
    "    return s[:-2] + new_char + s[-1]\n",
    "# DIRTY DATA: replace second last character in the minute column, '7' with '1'\n",
    "df_long['minute'] = df_long['minute'].apply(lambda x: replace_second_last_char_if_target(x, '1', '7'))\n",
    "df_long['hour'] = df_long['timestr'].str[:-2]\n",
    "df_long['hour'].replace(to_replace=\"\", value=\"00\", inplace=True)\n",
    "#df_long['Date'] = pd.to_datetime(df_long['Date'])\n",
    "df_long['Datetime'] = pd.to_datetime(df_long['Date'].dt.strftime('%Y-%m-%d') + ' ' + df_long['hour'] + ':' + df_long['Day'].astype(str) + ' ' + df_long['hour'] + ':' + df_long['minute'])\n",
    "# Format datetime string ()\n",
    "df_long['Datetime'] = df_long['Datetime'].dt.strftime('%Y-%m-%dT%H:%M-05')\n",
    "# Drop the extra fields\n",
    "df_long.drop(['timestr', 'minute', 'hour', 'Date'], axis=1, inplace=True)\n",
    "\n",
    "# -- Merge Sportfish data\n",
    "# -- \n",
    "merged_df = pd.merge(df_long, df_spt, left_on=['Station','Year','Month','SpeciesCode'], right_on=['Station','Year','Month','Species Code'], how='left').copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "###drop_these = ['Zone_y','Species Code','Common Name', 'Code']\n",
    "###merged_df.drop(columns=drop_these, inplace=True)\n",
    "\n",
    "\n",
    "# Re-rename Zone column that was renamed by merge\n",
    "merged_df = merged_df.rename(columns={'Zone_x': 'Zone'})\n",
    "\n",
    "# -- Merge species code data \n",
    "# --\n",
    "merged_df2 = pd.merge(merged_df, df_spc, left_on=['SpeciesCode'], right_on=['Code'], how='left').copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_these = ['Zone_y','Species Code','Common Name', 'Code']\n",
    "merged_df2.drop(columns=drop_these, inplace=True)\n",
    "\n",
    "\n",
    "# -- New dataframe: Group by Keyfield, add up total SpeciesCount \n",
    "# --\n",
    "grouped = merged_df2.groupby('Keyfield').agg({\n",
    "    'Keyfield': 'first',\n",
    "     'Station': 'first',\n",
    "     'Location': 'first',\n",
    "     'Latitude': 'first',\n",
    "     'Longitude': 'first',\n",
    "     'Year': 'first',\n",
    "     'Month': 'first',\n",
    "     'Day': 'first',\n",
    "     'Time': 'first',\n",
    "     'Zone': 'first',\n",
    "     'Area Towed': 'first',\n",
    "     'Salinity': 'first',\n",
    "     'Temperature': 'first',\n",
    "     'Grass  percent Cover rep 1': 'first',\n",
    "     'Grass  percent Cover rep 2': 'first',\n",
    "     'Grass  percent Cover rep 3': 'first',\n",
    "     'Grass  percent Cover rep 4': 'first',\n",
    "     'Grass  percent Cover rep 5': 'first',\n",
    "     'Grass  percent Cover rep 6': 'first',\n",
    "     'Grass  percent Cover rep 7': 'first',\n",
    "     'Grass  percent Cover rep 8': 'first',\n",
    "     'Grass  percent Cover rep 9': 'first',\n",
    "     'T  percent Cover rep 1': 'first',\n",
    "     'T  percent Cover rep 2': 'first',\n",
    "     'T  percent Cover rep 3': 'first',\n",
    "     'T  percent Cover rep 4': 'first',\n",
    "     'T  percent Cover rep 5': 'first',\n",
    "     'T  percent Cover rep 6': 'first',\n",
    "     'T  percent Cover rep 7': 'first',\n",
    "     'T  percent Cover rep 8': 'first',\n",
    "     'T  percent Cover rep 9': 'first',\n",
    "     'T Canopy Height rep 1': 'first',\n",
    "     'T Canopy Height rep 2': 'first',\n",
    "     'T Canopy Height rep 3': 'first',\n",
    "     'T Canopy Height rep 4': 'first',\n",
    "     'T Canopy Height rep 5': 'first',\n",
    "     'T Canopy Height rep 6': 'first',\n",
    "     'T Canopy Height rep 7': 'first',\n",
    "     'T Canopy Height rep 8': 'first',\n",
    "     'T Canopy Height rep 9': 'first',\n",
    "     'S  percent Cover rep 1': 'first',\n",
    "     'S  percent Cover rep 2': 'first',\n",
    "     'S  percent Cover rep 3': 'first',\n",
    "     'S  percent Cover rep 4': 'first',\n",
    "     'S  percent Cover rep 5': 'first',\n",
    "     'S  percent Cover rep 6': 'first',\n",
    "     'S  percent Cover rep 7': 'first',\n",
    "     'S  percent Cover rep 8': 'first',\n",
    "     'S  percent Cover rep 9': 'first',\n",
    "     'S Canopy Height rep 1': 'first',\n",
    "     'S Canopy Height rep 2': 'first',\n",
    "     'S Canopy Height rep 3': 'first',\n",
    "     'S Canopy Height rep 4': 'first',\n",
    "     'S Canopy Height rep 5': 'first',\n",
    "     'S Canopy Height rep 6': 'first',\n",
    "     'S Canopy Height rep 7': 'first',\n",
    "     'S Canopy Height rep 8': 'first',\n",
    "     'S Canopy Height rep 9': 'first',\n",
    "     'H  percent Cover rep 1': 'first',\n",
    "     'H  percent Cover rep 2': 'first',\n",
    "     'H  percent Cover rep 3': 'first',\n",
    "     'H  percent Cover rep 4': 'first',\n",
    "     'H  percent Cover rep 5': 'first',\n",
    "     'H  percent Cover rep 6': 'first',\n",
    "     'H  percent Cover rep 7': 'first',\n",
    "     'H  percent Cover rep 8': 'first',\n",
    "     'H  percent Cover rep 9': 'first',\n",
    "     'H Canopy Height Rep 1': 'first',\n",
    "     'H Canopy Height Rep 2': 'first',\n",
    "     'H Canopy Height Rep 3': 'first',\n",
    "     'H Canopy Height Rep 4': 'first',\n",
    "     'H Canopy Height Rep 5': 'first',\n",
    "     'H Canopy Height Rep 6': 'first',\n",
    "     'H Canopy Height Rep 7': 'first',\n",
    "     'H Canopy Height Rep 8': 'first',\n",
    "     'H Canopy Height Rep 9': 'first',\n",
    "     'SAV percent Cover rep 1': 'first',\n",
    "     'SAV percent Cover rep 2': 'first',\n",
    "     'SAV percent Cover rep 3': 'first',\n",
    "     'SAV percent Cover rep 4': 'first',\n",
    "     'SAV percent Cover rep 5': 'first',\n",
    "     'SAV percent Cover rep 6': 'first',\n",
    "     'SAV percent Cover rep 7': 'first',\n",
    "     'SAV percent Cover rep 8': 'first',\n",
    "     'SAV percent Cover rep 9': 'first',\n",
    "     'Total percent Cover rep 1': 'first',\n",
    "     'Total percent Cover rep 2': 'first',\n",
    "     'Total percent Cover rep 3': 'first',\n",
    "     'Total percent Cover rep 4': 'first',\n",
    "     'Total percent Cover rep 5': 'first',\n",
    "     'Total percent Cover rep 6': 'first',\n",
    "     'Total percent Cover rep 7': 'first',\n",
    "     'Total percent Cover rep 8': 'first',\n",
    "     'Total percent Cover rep 9': 'first',\n",
    "     'Algae percent Cover rep 1': 'first',\n",
    "     'Algae percent Cover rep 2': 'first',\n",
    "     'Algae percent Cover rep 3': 'first',\n",
    "     'Algae percent Cover rep 4': 'first',\n",
    "     'Algae percent Cover rep 5': 'first',\n",
    "     'Algae percent Cover rep 6': 'first',\n",
    "     'Algae percent Cover rep 7': 'first',\n",
    "     'Algae percent Cover rep 8': 'first',\n",
    "     'Algae percent Cover rep 9': 'first',\n",
    "     'Cyn Density': 'first',\n",
    "     'Average Grass percent Cover': 'first',\n",
    "     'Average T percent Cover': 'first',\n",
    "     'Average S percent Cover': 'first',\n",
    "     'Average H percent Cover': 'first',\n",
    "     'Average T Canopy Height': 'first',\n",
    "     'Average S Canopy Height': 'first',\n",
    "     'Average H Canopy Height': 'first',\n",
    "     'SpeciesCode': 'first',\n",
    "     'SpeciesCount': 'sum',\n",
    "     'Datetime': 'first',\n",
    "     'Length (mm)': 'sum',\n",
    "     'Species': 'first',\n",
    "     'Common name': 'first'\n",
    "})\n",
    "\n",
    "# Save Lines where SpeciesCount is zero: no need to have duplicates of these in the data\n",
    "zerocounts_df = grouped[grouped['SpeciesCount'] == 0].copy()\n",
    "\n",
    "# -- 1) Delete from the merged dataframe all lines with Keyfield value found in zerocounts_df \n",
    "# -- 2) Delete from the merged dataframe all lines with SpeciesCount == 0\n",
    "# -- 3) Concatenate back in one line per Keyfield that had zero total SpeciesCount (to preserve )\n",
    "# -- (No added value as all counts are 0)\n",
    "# -- \n",
    "values_to_drop = zerocounts_df['Keyfield'].unique()\n",
    "merged_df2.drop(merged_df2[merged_df2['Keyfield'].isin(values_to_drop)].index, inplace=True)\n",
    "# Delete from the merged dataframe other lines with zero counts (some species in the sample are present)\n",
    "merged_df2.drop(merged_df2[merged_df2['SpeciesCount'] == 0].index, inplace=True)\n",
    "# Concatenate with the zero count dataframe (to keep the benthic coverage data, but just one line per Keyfield / sample)\n",
    "concat_df =  pd.concat([merged_df2, zerocounts_df], ignore_index=True)\n",
    "\n",
    "# Sort by date/sample\n",
    "df_sorted = concat_df.sort_values(by='Keyfield').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns\n",
    "df_sorted = df_sorted.rename(columns={'Common name': 'CommonName', 'Length (mm)': 'IndividualLength'})\n",
    "# print sorted cols, Collection Stn columns -> join 'by' which columns???\n",
    "df_sorted.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted[df_sorted['Keyfield'] == 201508022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???( merge Collection Stn data????)\n",
    "# !!! OBS !!!\n",
    "# - Sportfish Data that is included in Collection Stn already in df_sorted, plus in som cases at least has better coverage in Sportfish sheet!!\n",
    "# -> Do not duplcate these data (... by reading the same data from Collection Stn data...)\n",
    "#    -> either REMOVE these data from Collection Stn data before merging to df_sorted..., or\n",
    "#    -> publish the Collection Stn data separately!???\n",
    "\n",
    "# Also, for collection Stn data:\n",
    "# 1) clean the length data: DROP rows where Length NaN\n",
    "# 2) Make sure length etc column types float!\n",
    "# 3) IF DATA TO BE ADDED TO SPORTFISH DATA : Rename columns  by adding _Collection to separate from the sportfish length filelds!???\n",
    "\n",
    "# RECOMMENDATION : HAVE SEPARATE datasets\n",
    "# 1) (All data + Sportfish lengths) AND (All data + Collection Stn lengths)\n",
    "# 2) OR:  ( All data (counts) ) plus (Sportfish Data (lengths)) plus (Collection Stn Data (lengths))\n",
    "#     2.1) Have Keyfield column in all to have a common ID (need to build it for sportfish and collection stn ...)\n",
    "\n",
    "\n",
    "df_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23366540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Make dictionary for variable descriptions\n",
    "# --\n",
    "\n",
    "# Read the sheet into a DataFrame\n",
    "df_dscrn = pd.read_excel(sourcefile, sheet_name='Header Key')\n",
    "\n",
    "# Convert the two columns to a dictionary\n",
    "# Assumption: first column is key, second column is value\n",
    "descr_dict = dict(zip(df_dscrn.iloc[:,0], df_dscrn.iloc[:,1]))\n",
    "\n",
    "# Remove keys that no longer exist in the data frame\n",
    "keys_to_remove = ['Ari', 'Arp', 'Bab', 'Chf', 'Cyn ALL Lengths', 'Cyn (lengths 30-200 mm)', 'Cyn (lengths 30-200 mm) pres/abs only', 'Epi', 'Has', 'Hie', 'Hpa', 'Hyp', 'Lam', 'Lar', 'Lug (lengths 30-260 mm)', 'Lug (lengths 30-260 mm)  pres/abs only', 'Lum', 'Lun', 'Lus', 'Mym', 'Occ', 'Paa', 'Pab', 'Pal', 'Poc', 'Scb', 'Sco', 'Sev', 'Spa']\n",
    "for key in keys_to_remove:\n",
    "    descr_dict.pop(key, None)  # Safe: does nothing if key missing\n",
    "descr_dict_new = {k.replace('%', 'percent'): v.replace('%', 'percent') for k, v in descr_dict.items()}\n",
    "\n",
    "print(descr_dict_new)\n",
    "\n",
    "# Add description to the dict for the new variables: SpeciesCode and count\n",
    "\n",
    "## The descriptions can be used for writing out description field to the ERDDAP datasets XMl snippet\n",
    "# !!! JATKA !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the two CSVs\n",
    "df_all = pd.read_csv(\"AllData.csv\")  # Exported from the original Excel sheet\n",
    "df_stn = pd.read_csv(\"CollectionData.csv\")  # The one you just uploaded\n",
    "\n",
    "# Merge based on key fields\n",
    "merged_df = pd.merge(df_all, df_stn, on=[\"Station\", \"Date\", \"Year\", \"Month\", \"Day\"], how=\"inner\")\n",
    "\n",
    "# Save the merged result\n",
    "merged_df.to_csv(\"Merged_Sportfish_Data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ioos)",
   "language": "python",
   "name": "ioos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
